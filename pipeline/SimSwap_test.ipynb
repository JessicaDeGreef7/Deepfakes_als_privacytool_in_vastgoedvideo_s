{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb79e3b",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start due to the missing module '_sqlite3'. Consider installing this module.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresMissingModule'>here</a> for more info."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a43d393",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start due to the missing module '_sqlite3'. Consider installing this module.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresMissingModule'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "#################################################\n",
    "#                   Imports                     #\n",
    "#################################################\n",
    "\n",
    "import sys\n",
    "\n",
    "############## imports RetinaFace ###############\n",
    "import tensorflow as tf\n",
    "\n",
    "from retinaface import RetinaFace\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "sys.path.insert(0, '../RetinaFace/deepface')\n",
    "from deepface import DeepFace\n",
    "import pandas as pd\n",
    "# import tensorflow as tf\n",
    "\n",
    "############## imports Image2text  ##############\n",
    "import torch\n",
    "from lavis.models import load_model_and_preprocess\n",
    "\n",
    "########### imports Stable diffusion ############\n",
    "from diffusers import StableDiffusionPipeline\n",
    "\n",
    "################ imports SimSwap ################\n",
    "import os\n",
    "import sys\n",
    "# # caution: path[0] is reserved for script path (or '' in REPL)\n",
    "#sys.path.insert(1, '../Deepfake/SimSwap')\n",
    "\n",
    "# #import test_multi_video_swapsingle\n",
    "from insightface_func.face_detect_crop_multi import Face_detect_crop\n",
    "# # adding Folder_SimSwap to the system path\n",
    "sys.path.insert(0, '../Deepfake/SimSwap')\n",
    "from models.models import create_model\n",
    "from options.test_options import TestOptions\n",
    "import glob\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F\n",
    "from util.reverse2original import reverse2wholeimage\n",
    "from moviepy.video.io.ImageSequenceClip import ImageSequenceClip\n",
    "from parsing_model.model import BiSeNet\n",
    "from util.norm import SpecificNorm\n",
    "\n",
    "\n",
    "import nvidia_smi\n",
    "import gc\n",
    "\n",
    "#################################################\n",
    "#              Globale variabele                #\n",
    "############################################SS#####\n",
    "\n",
    "aantal_gezichten_gedetecteerd = 0\n",
    "herkende_gezichten_embedding = pd.DataFrame()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "multisepcific_dir = \"../images/wissel/\"\n",
    "temp_results_dir='./temp_results'  \n",
    "save_path = \"./output/test.mp4\" \n",
    "#torch.cuda.empty_cache()\n",
    "torch.cuda.memory_summary(device=None, abbreviated=False)\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF']='expandable_segments:True, max_split_size_mb:512'\n",
    "\n",
    "#################################################\n",
    "#                   Code                        #\n",
    "#################################################\n",
    "\n",
    "def wetenOverGPU():\n",
    "    nvidia_smi.nvmlInit()\n",
    "\n",
    "    handle = nvidia_smi.nvmlDeviceGetHandleByIndex(0)\n",
    "    # card id 0 hardcoded here, there is also a call to get all available card ids, so we could iterate\n",
    "\n",
    "    info = nvidia_smi.nvmlDeviceGetMemoryInfo(handle)\n",
    "\n",
    "    print(\"Total memory:\", info.total)\n",
    "    print(\"Free memory:\", info.free)\n",
    "    print(\"Used memory:\", info.used)\n",
    "\n",
    "    nvidia_smi.nvmlShutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a72499",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start due to the missing module '_sqlite3'. Consider installing this module.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresMissingModule'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "def simSwap(video, frames_met_gezichten, img):\n",
    "    # img = cv2 rgb 512, 512, 3 \n",
    "    # omzetten naar tensor met extra dim batch # len =4 b,h,w,c\n",
    "    transformer_Arcface = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "    opt = TestOptions().parse()\n",
    "\n",
    "    print('./insightface_func/models')\n",
    "    app = Face_detect_crop(name='antelope', root='./insightface_func/models')\n",
    "    app.prepare(ctx_id= 0, det_thresh=0.0, det_size=(640,640),mode='None')\n",
    "\n",
    "    torch.nn.Module.dump_patches = True\n",
    "    model = create_model(opt)\n",
    "    model.eval()\n",
    "\n",
    "    vcap = cv2.VideoCapture(video)\n",
    "    if not vcap.isOpened():\n",
    "        print(\"Can't open camera!\")\n",
    "        exit()\n",
    "\n",
    "    frame_count = int(vcap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    fps = vcap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    # while ret:\n",
    "    for frame_index in range(100): \n",
    "\n",
    "        # read a frame\n",
    "        ret, frame = vcap.read()\n",
    "        #print(type(frame))\n",
    "        # ret == True if frame read correctly\n",
    "        if not ret:\n",
    "            print(\"Can't read frame, exiting...\")\n",
    "            break\n",
    "        #wetenOverGPU()\n",
    "        # The specific person to be swapped(source)\n",
    "        if frame_index in frames_met_gezichten:\n",
    "            if aantal_gezichten_gedetecteerd == 1:\n",
    "                single_face_video_swap(frame, frame_index, opt, app, model, transformer_Arcface)\n",
    "            else:\n",
    "                target_id_norm_list, source_specific_id_nonorm_list = get_images_for_multi_videoswap(app, model, transformer_Arcface)\n",
    "                \n",
    "                #wetenOverGPU()\n",
    "                #print(\"--------video path----------\")\n",
    "                multi_video_swap(frame, frame_index, target_id_norm_list,source_specific_id_nonorm_list, opt.id_thres, model, app)\n",
    "        else:\n",
    "            if not os.path.exists(temp_results_dir):\n",
    "                os.mkdir(temp_results_dir)\n",
    "            frame = frame.astype(np.uint8)\n",
    "            cv2.imwrite(os.path.join(temp_results_dir, 'frame_{:0>7d}.jpg'.format(frame_index)), frame)\n",
    "\n",
    "    model.to(\"cpu\")\n",
    "\n",
    "    # everything done\n",
    "    # - release capture\n",
    "    # - release video writer\n",
    "    # - destroy all windows\n",
    "    print(\"Retinaface done\")\n",
    "    vcap.release()\n",
    "    #output.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    print(\"maak video\")\n",
    "\n",
    "\n",
    "    return fps\n",
    "\n",
    "def single_face_video_swap(frame, frame_index, opt, app, model, transformer_Arcface):\n",
    "    crop_size = 224\n",
    "    transformer = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            #transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "    transformer_Arcface = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        img = cv2.imread(\"../images/wissel/DST_1.jpg\")\n",
    "        #print(\"????????????????????????????????????\")\n",
    "        img_a_align_crop, _ = app.get(img,crop_size)\n",
    "        img_a_align_crop_pil = Image.fromarray(cv2.cvtColor(img_a_align_crop[0],cv2.COLOR_BGR2RGB)) \n",
    "        img_a = transformer_Arcface(img_a_align_crop_pil)\n",
    "        img_id = img_a.view(-1, img_a.shape[0], img_a.shape[1], img_a.shape[2])\n",
    "\n",
    "        # pic_b = opt.pic_b_path\n",
    "        # img_b_whole = cv2.imread(pic_b)\n",
    "        # img_b_align_crop, b_mat = app.get(img_b_whole,crop_size)\n",
    "        # img_b_align_crop_pil = Image.fromarray(cv2.cvtColor(img_b_align_crop,cv2.COLOR_BGR2RGB)) \n",
    "        # img_b = transformer(img_b_align_crop_pil)\n",
    "        # img_att = img_b.view(-1, img_b.shape[0], img_b.shape[1], img_b.shape[2])\n",
    "\n",
    "        # convert numpy to tensor\n",
    "        img_id = img_id.cuda()\n",
    "        # img_att = img_att.cuda()\n",
    "\n",
    "        #create latent id\n",
    "        img_id_downsample = F.interpolate(img_id, size=(112,112))\n",
    "        latend_id = model.netArc(img_id_downsample)\n",
    "        latend_id = F.normalize(latend_id, p=2, dim=1)\n",
    "\n",
    "        single_video_swap(frame, frame_index, latend_id, model, app, opt.output_path)\n",
    "\n",
    "def single_video_swap(frame, frame_index, id_vetor, swap_model, detect_model, temp_results_dir = './temp_results'):\n",
    "\n",
    "    \n",
    "    crop_size = 224\n",
    "    use_mask = False\n",
    "\n",
    "    spNorm = SpecificNorm()\n",
    "    #swap_model.cpu()\n",
    "    #reverse2wholeimage.cpu()\n",
    "\n",
    "    #wetenOverGPU()\n",
    "    # while ret:\n",
    "    detect_results = detect_model.get(frame,crop_size)\n",
    "\n",
    "    if detect_results is not None:\n",
    "        # print(frame_index)\n",
    "        #wetenOverGPU()\n",
    "        if not os.path.exists(temp_results_dir):\n",
    "                os.mkdir(temp_results_dir)\n",
    "        frame_align_crop_list = detect_results[0]\n",
    "        frame_mat_list = detect_results[1]\n",
    "        swap_result_list = []\n",
    "        frame_align_crop_tenor_list = []\n",
    "        #wetenOverGPU()\n",
    "\n",
    "        for frame_align_crop in range(6000000000):\n",
    "\n",
    "            # BGR TO RGB\n",
    "            # frame_align_crop_RGB = frame_align_crop[...,::-1]\n",
    "\n",
    "            frame_align_crop_tenor = _totensor(cv2.cvtColor(frame_align_crop_list[0],cv2.COLOR_BGR2RGB))[None,...].cuda()\n",
    "\n",
    "            swap_result = swap_model(None, frame_align_crop_tenor, id_vetor, None, True)[0]\n",
    "            cv2.imwrite(os.path.join(temp_results_dir, 'frame_{:0>7d}.jpg'.format(frame_index)), frame)\n",
    "            swap_result_list.append(swap_result)\n",
    "            frame_align_crop_tenor_list.append(frame_align_crop_tenor)\n",
    "#\n",
    " \n",
    "        wetenOverGPU()\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "        #wetenOverGPU()\n",
    "\n",
    "        reverse2wholeimage(frame_align_crop_tenor_list,swap_result_list, frame_mat_list, crop_size, frame, \\\n",
    "            os.path.join(temp_results_dir, 'frame_{:0>7d}.jpg'.format(frame_index)), norm = spNorm)\n",
    "\n",
    "    else:\n",
    "        if not os.path.exists(temp_results_dir):\n",
    "            os.mkdir(temp_results_dir)\n",
    "        frame = frame.astype(np.uint8)\n",
    "        cv2.imwrite(os.path.join(temp_results_dir, 'frame_{:0>7d}.jpg'.format(frame_index)), frame)\n",
    "\n",
    "def get_images_for_multi_videoswap(app, model, transformer_Arcface):\n",
    "    \n",
    "    crop_size = 244\n",
    "    source_specific_id_nonorm_list = []\n",
    "    print(\"-------test-------------\")\n",
    "    source_path = os.path.join(multisepcific_dir,'SRC_*')\n",
    "    print(source_path)\n",
    "    source_specific_images_path = sorted(glob.glob(source_path))\n",
    "    print(source_specific_images_path)\n",
    "    with torch.no_grad():\n",
    "        for source_specific_image_path in source_specific_images_path:\n",
    "            #print(source_specific_image_path)\n",
    "            specific_person_whole = cv2.imread(source_specific_image_path)\n",
    "            #print(specific_person_whole)\n",
    "            specific_person_align_crop, _ = app.get(specific_person_whole,crop_size)\n",
    "            specific_person_align_crop_pil = Image.fromarray(cv2.cvtColor(specific_person_align_crop[0],cv2.COLOR_BGR2RGB)) \n",
    "            specific_person = transformer_Arcface(specific_person_align_crop_pil)\n",
    "            specific_person = specific_person.view(-1, specific_person.shape[0], specific_person.shape[1], specific_person.shape[2])\n",
    "            # convert numpy to tensor\n",
    "            specific_person = specific_person.cuda()\n",
    "            #create latent id\n",
    "            specific_person_downsample = F.interpolate(specific_person, size=(112,112))\n",
    "            specific_person_id_nonorm = model.netArc(specific_person_downsample)\n",
    "            source_specific_id_nonorm_list.append(specific_person_id_nonorm.clone())\n",
    "\n",
    "\n",
    "        # The person who provides id information (list)\n",
    "        target_id_norm_list = []\n",
    "        target_path = os.path.join(multisepcific_dir,'DST_*')\n",
    "        print(target_path)\n",
    "        target_images_path = sorted(glob.glob(target_path))\n",
    "        print(target_images_path)\n",
    "        \n",
    "        for target_image_path in target_images_path:\n",
    "            img_a_whole = cv2.imread(target_image_path)\n",
    "            print(target_image_path)\n",
    "            img_a_align_crop, _ = app.get(img_a_whole,crop_size)\n",
    "            img_a_align_crop_pil = Image.fromarray(cv2.cvtColor(img_a_align_crop[0],cv2.COLOR_BGR2RGB)) \n",
    "            img_a = transformer_Arcface(img_a_align_crop_pil)\n",
    "            img_id = img_a.view(-1, img_a.shape[0], img_a.shape[1], img_a.shape[2])\n",
    "            # convert numpy to tensor\n",
    "            img_id = img_id.cuda()\n",
    "            #create latent id\n",
    "            img_id_downsample = F.interpolate(img_id, size=(112,112))\n",
    "            latend_id = model.netArc(img_id_downsample)\n",
    "            latend_id = F.normalize(latend_id, p=2, dim=1)\n",
    "            target_id_norm_list.append(latend_id.clone())\n",
    "\n",
    "        assert len(target_id_norm_list) == len(source_specific_id_nonorm_list), \"The number of images in source and target directory must be same !!!\"\n",
    "    return source_specific_id_nonorm_list, target_id_norm_list\n",
    "\n",
    "def multi_video_swap(frame, frame_index, target_id_norm_list,source_specific_id_nonorm_list, id_thres, swap_model, detect_model):\n",
    "    wetenOverGPU()\n",
    "    crop_size = 224\n",
    "    no_simswaplogo = True\n",
    "    logoclass = None\n",
    "\n",
    "    spNorm = SpecificNorm()\n",
    "    mse = torch.nn.MSELoss().cuda()\n",
    "\n",
    "    # while ret:\n",
    "    detect_results = detect_model.get(frame,crop_size)\n",
    "    print(\"a\")\n",
    "    if detect_results is not None:\n",
    "        # print(frame_index)\n",
    "        if not os.path.exists(temp_results_dir):\n",
    "                os.mkdir(temp_results_dir)\n",
    "        frame_align_crop_list = detect_results[0]\n",
    "        print(f\"lengte van frame_align_crop_list: {len(frame_align_crop_list)}\")\n",
    "        frame_mat_list = detect_results[1]\n",
    "\n",
    "        print(\"b\")\n",
    "        wetenOverGPU()\n",
    "        id_compare_values = [] \n",
    "        frame_align_crop_tenor_list = []\n",
    "        for frame_align_crop in frame_align_crop_list:\n",
    "\n",
    "            # BGR TO RGB\n",
    "            # frame_align_crop_RGB = frame_align_crop[...,::-1]\n",
    "\n",
    "            frame_align_crop_tenor = _totensor(cv2.cvtColor(frame_align_crop,cv2.COLOR_BGR2RGB))[None,...].cuda()\n",
    "            #print(\"hier\")\n",
    "            frame_align_crop_tenor_arcnorm = spNorm(frame_align_crop_tenor)\n",
    "            #print(\"o\")\n",
    "            frame_align_crop_tenor_arcnorm_downsample = F.interpolate(frame_align_crop_tenor_arcnorm, size=(112,112))#.cpu()\n",
    "            #print(\"l\")\n",
    "            frame_align_crop_crop_id_nonorm = swap_model.netArc(frame_align_crop_tenor_arcnorm_downsample)#.cpu()\n",
    "            #print(\"huh\")\n",
    "            id_compare_values.append([])\n",
    "            #print(\"nee\")\n",
    "            for source_specific_id_nonorm_tmp in source_specific_id_nonorm_list:\n",
    "                id_compare_values[-1].append(mse(frame_align_crop_crop_id_nonorm,source_specific_id_nonorm_tmp).detach().cpu().numpy())\n",
    "                #print(\"m\")\n",
    "            frame_align_crop_tenor_list.append(frame_align_crop_tenor)\n",
    "            break\n",
    "        torch.cuda.empty_cache()\n",
    "        print(\"c\")\n",
    "        id_compare_values_array = np.array(id_compare_values).transpose(1,0)\n",
    "        wetenOverGPU()\n",
    "        try:\n",
    "            min_indexs = np.argmin(id_compare_values_array,axis=0)\n",
    "            #print(min_indexs)\n",
    "        except ValueError:\n",
    "            print(\" \")\n",
    "        min_value = np.min(id_compare_values_array,axis=0)\n",
    "        print(\"d\")\n",
    "        #print(min_value)\n",
    "        swap_result_list = [] \n",
    "        swap_result_matrix_list = []\n",
    "        swap_result_ori_pic_list = []\n",
    "        wetenOverGPU()\n",
    "        for tmp_index, min_index in enumerate(min_indexs):\n",
    "            #os.environ['PYTORCH_CUDA_ALLOC_CONF']='expandable_segments:True, max_split_size_mb:512'\n",
    "            #os.environ[\"SUNO_USE_SMALL_MODELS\"] = \"True\"\n",
    "            #os.environ[\"SUNO_OFFLOAD_CPU\"] = \"True\"\n",
    "            if min_value[tmp_index] < id_thres:\n",
    "                swap_result = swap_model(None, frame_align_crop_tenor_list[tmp_index], target_id_norm_list[min_index], None, True)[0]\n",
    "                print(\"hier-\")\n",
    "                wetenOverGPU()\n",
    "                swap_result_list.append(swap_result)\n",
    "                swap_result_matrix_list.append(frame_mat_list[tmp_index])\n",
    "                swap_result_ori_pic_list.append(frame_align_crop_tenor_list[tmp_index])\n",
    "                print(\"m\")\n",
    "                wetenOverGPU()\n",
    "            else:\n",
    "                pass\n",
    "            wetenOverGPU()\n",
    "        #os.environ['PYTORCH_CUDA_ALLOC_CONF']='expandable_segments:True, max_split_size_mb:512'\n",
    "        print(\"e\")\n",
    "\n",
    "\n",
    "        if len(swap_result_list) !=0:\n",
    "            print(\"wissel gebeurt\")\n",
    "            reverse2wholeimage(swap_result_ori_pic_list,swap_result_list, swap_result_matrix_list, crop_size, frame, logoclass,\\\n",
    "                os.path.join(temp_results_dir, 'frame_{:0>7d}.jpg'.format(frame_index)), pasring_model = None, use_mask = False, norm = spNorm)\n",
    "        else:\n",
    "            if not os.path.exists(temp_results_dir):\n",
    "                os.mkdir(temp_results_dir)\n",
    "            frame = frame.astype(np.uint8)\n",
    "            if not no_simswaplogo:\n",
    "                frame = logoclass.apply_frames(frame)\n",
    "            cv2.imwrite(os.path.join(temp_results_dir, 'frame_{:0>7d}.jpg'.format(frame_index)), frame)\n",
    "        print(\"f\")\n",
    "    else:\n",
    "        if not os.path.exists(temp_results_dir):\n",
    "            os.mkdir(temp_results_dir)\n",
    "        frame = frame.astype(np.uint8)\n",
    "        cv2.imwrite(os.path.join(temp_results_dir, 'frame_{:0>7d}.jpg'.format(frame_index)), frame)\n",
    "    print(\"e\")\n",
    "    return\n",
    "\n",
    "def _totensor(array):\n",
    "    tensor = torch.from_numpy(array)\n",
    "    img = tensor.transpose(0, 1).transpose(0, 2).contiguous()\n",
    "    return img.float().div(255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372241d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "aantal_gezichten_gedetecteerd = 1\n",
    "#if not os.path.exists(multisepcific_dir):\n",
    "#    os.mkdir(temp_results_dir)\n",
    "#else:\n",
    "#    os.system('rm -rf ' +multisepcific_dir + '*')\n",
    "#print(\"test\")\n",
    "#wetenOverGPU() # moet ongeveer 8G vrij hebben\n",
    "orginele_video = '/home/student/Documents/AnyDesk/masterproef/images/gezicht2.mp4'\n",
    "\n",
    "#retinaface_frames_met_gezichten = retinaface(orginele_video)\n",
    "#print(retinaface_frames_met_gezichten[:10])\n",
    "#antwoorden = image2text()\n",
    "#print(antwoorden)\n",
    "#img = stableDiffussion(antwoorden) # returns an image (fake face)\n",
    "# cv2.img in rgb shape = (512, 512, 3)\n",
    "crop_size = 512\n",
    "\n",
    "img = cv2.imread(\"../images/wissel/DST_1.jpg\")\n",
    "img_cropped = img[:crop_size,:crop_size]\n",
    "retinaface_frames_met_gezichten = range(50)\n",
    "fps = simSwap(orginele_video, retinaface_frames_met_gezichten, img_cropped) # afbeelding van stable diffusion\n",
    "wetenOverGPU()\n",
    "#print(\"RetinaFace gelukt\")\n",
    "\n",
    "# image_filename_list = []\n",
    "\n",
    "path = os.path.join(temp_results_dir,'*.jpg')\n",
    "image_filenames = sorted(glob.glob(path))\n",
    "print(image_filenames)\n",
    "\n",
    "clips = ImageSequenceClip(image_filenames,fps = fps)\n",
    "clips.write_videofile(save_path, codec=\"libx264\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
